{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92a58d2-e80d-4d73-aceb-487214a1cbf5",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "### Daniel Mehta\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfeb197-8fb2-49b6-a2b7-83e563ef5a61",
   "metadata": {},
   "source": [
    "## Introduction and Problem Statement\n",
    "\n",
    "**Business Problem**  \n",
    "Exchange-Traded Funds (ETFs) are popular investment products, but creating them manually requires extensive research and portfolio balancing.  \n",
    "I propose an **AI-driven ETF grouping system** that automatically clusters stocks in the S&P 500 into ETF-style groups based on investment-relevant characteristics such as volatility, return, momentum, and liquidity.\n",
    "\n",
    "These clusters could be used by financial institutions or fintech platforms to quickly generate investment ideas for different risk profiles and objectives. For example, aggressive growth, stable income, or balanced diversification.\n",
    "\n",
    "**Note on Feature Selection**  \n",
    "My original concept included sector classification as a feature, but the available dataset does not contain sector information.  \n",
    "To maintain project simplicity and avoid external data merging, this implementation will focus solely on numerical, market-derived features.\n",
    "\n",
    "**Goal**  \n",
    "Build a stock clustering pipeline that:  \n",
    "1. Processes historical price data for S&P 500 companies.  \n",
    "2. Creates numerical feature vectors for each stock.  \n",
    "3. Applies and compares **K-Means Clustering** (covered in course) and **Hierarchical Clustering** (new) to group the stocks.  \n",
    "4. Evaluates clusters using quantitative metrics and visualizations.  \n",
    "5. Recommends the optimal approach for deployment in an ETF grouping tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f7d7f9-bb3f-4c28-8b8f-c0fc404f5569",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78ce0f96-9446-4693-b9d2-895093abc104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17ad8f1-99aa-444d-bc4d-be5b837320b1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Load Dataset / Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffbb8c8b-767e-4ed5-a97b-ed5c9813dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"all_stocks_5yr.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c91beb6-123f-43c9-80ec-63c8a5ee3b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 619040 entries, 0 to 619039\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   date    619040 non-null  object \n",
      " 1   open    619029 non-null  float64\n",
      " 2   high    619032 non-null  float64\n",
      " 3   low     619032 non-null  float64\n",
      " 4   close   619040 non-null  float64\n",
      " 5   volume  619040 non-null  int64  \n",
      " 6   Name    619040 non-null  object \n",
      "dtypes: float64(4), int64(1), object(2)\n",
      "memory usage: 33.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(         date   open   high    low  close    volume Name\n",
       " 0  2013-02-08  15.07  15.12  14.63  14.75   8407500  AAL\n",
       " 1  2013-02-11  14.89  15.01  14.26  14.46   8882000  AAL\n",
       " 2  2013-02-12  14.45  14.51  14.10  14.27   8126000  AAL\n",
       " 3  2013-02-13  14.30  14.94  14.25  14.66  10259500  AAL\n",
       " 4  2013-02-14  14.94  14.96  13.16  13.99  31879900  AAL,\n",
       " None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(),df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1e5e86e-8ed1-43f4-ab9f-3932959e3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting date to datetime\n",
    "df['date'] =pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "797bc5be-d093-4af3-b16e-732dad797f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " date       0\n",
      "open      11\n",
      "high       8\n",
      "low        8\n",
      "close      0\n",
      "volume     0\n",
      "Name       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for missing values\n",
    "print(\"Missing values per column:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2953e06-3a15-4c8c-b948-85cfab818399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing open, high, low, close values\n",
    "df = df.dropna(subset=['open', 'high', 'low', 'close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dcfd19e-a805-4fdb-a6d3-544ead7abe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking correct data types\n",
    "numeric_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "df[numeric_cols] = df[numeric_cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dacf5f4-b376-4bb7-9811-08679e929480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removeing any duplicates\n",
    "df = df.drop_duplicates(subset=['date', 'Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbff8596-609e-40b8-8ab3-d41fdd53edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Name then date\n",
    "df =df.sort_values(by=['Name','date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "521ab99f-3954-44fe-9af3-118b2dee0b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset shape: (619029, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>45.07</td>\n",
       "      <td>45.35</td>\n",
       "      <td>45.00</td>\n",
       "      <td>45.08</td>\n",
       "      <td>1824755.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>45.17</td>\n",
       "      <td>45.18</td>\n",
       "      <td>44.45</td>\n",
       "      <td>44.60</td>\n",
       "      <td>2915405.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-12</td>\n",
       "      <td>44.81</td>\n",
       "      <td>44.95</td>\n",
       "      <td>44.50</td>\n",
       "      <td>44.62</td>\n",
       "      <td>2373731.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>44.81</td>\n",
       "      <td>45.24</td>\n",
       "      <td>44.68</td>\n",
       "      <td>44.75</td>\n",
       "      <td>2052338.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>44.72</td>\n",
       "      <td>44.78</td>\n",
       "      <td>44.36</td>\n",
       "      <td>44.58</td>\n",
       "      <td>3826245.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   open   high    low  close     volume Name\n",
       "0 2013-02-08  45.07  45.35  45.00  45.08  1824755.0    A\n",
       "1 2013-02-11  45.17  45.18  44.45  44.60  2915405.0    A\n",
       "2 2013-02-12  44.81  44.95  44.50  44.62  2373731.0    A\n",
       "3 2013-02-13  44.81  45.24  44.68  44.75  2052338.0    A\n",
       "4 2013-02-14  44.72  44.78  44.36  44.58  3826245.0    A"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Cleaned dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d85de-c7c6-40d4-9f19-020a3305b433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (moflow)",
   "language": "python",
   "name": "moflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
